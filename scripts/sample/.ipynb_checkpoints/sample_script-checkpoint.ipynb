{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3849a2cd-03b0-46c0-9e46-e05ed04f3412",
   "metadata": {},
   "source": [
    "## Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92ed236-e7f5-4239-b9b0-3489c684cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "print('Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8434100-8690-4bfc-afae-7babc0b73e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize(project = 'glacier-probe-model-475519')\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project = 'glacier-probe-model-475519')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66debf43-25da-4443-9724-e116fd61c74e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Hasdeo Forest RGB Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ac0a10f-c13e-4813-b00f-11209f893138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Earth Engine initialized for project: glacier-probe-model-475519\n",
      "======================================================================\n",
      "HASDEO FOREST IMAGE DOWNLOADER - RGB VIEWABLE VERSION\n",
      "Targeting Central Hasdeo Region: [82.75, 22.95, 82.85, 23.05]\n",
      "======================================================================\n",
      "‚úì Created output directories in hasdeo_forest_dataset_rgb/\n",
      "\n",
      "Target: 50 images (Max Cloud Cover: 30%)\n",
      "Time periods: 7\n",
      "Resolution: 30m | Format: PNG (Viewable RGB)\n",
      "\n",
      "üå≥ Starting Downloads for: Hasdeo_Arand_Zoomed\n",
      "----------------------------------------------------------------------\n",
      "  2018: 11 images available\n",
      "    ‚Üì 2018-01-21... ‚úì (1/50)\n",
      "    ‚Üì 2018-01-31... ‚úì (2/50)\n",
      "    ‚Üì 2018-02-15... ‚úì (3/50)\n",
      "    ‚Üì 2018-03-07... ‚úì (4/50)\n",
      "    ‚Üì 2018-03-12... ‚úì (5/50)\n",
      "    ‚Üì 2018-04-21... ‚úì (6/50)\n",
      "    ‚Üì 2018-11-07... ‚úì (7/50)\n",
      "    ‚Üì 2018-11-17... ‚úì (8/50)\n",
      "    ‚Üì 2018-12-07... ‚úì (9/50)\n",
      "    ‚Üì 2018-12-22... ‚úì (10/50)\n",
      "  2019: 41 images available\n",
      "    ‚Üì 2019-01-01... ‚úì (11/50)\n",
      "    ‚Üì 2019-01-06... ‚úì (12/50)\n",
      "    ‚Üì 2019-01-11... ‚úì (13/50)\n",
      "    ‚Üì 2019-01-16... ‚úì (14/50)\n",
      "    ‚Üì 2019-01-21... ‚úì (15/50)\n",
      "    ‚Üì 2019-01-31... ‚úì (16/50)\n",
      "    ‚Üì 2019-02-05... ‚úì (17/50)\n",
      "    ‚Üì 2019-02-10... ‚úì (18/50)\n",
      "    ‚Üì 2019-02-20... ‚úì (19/50)\n",
      "    ‚Üì 2019-03-02... ‚úì (20/50)\n",
      "  2020: 34 images available\n",
      "    ‚Üì 2020-01-06... ‚úì (21/50)\n",
      "    ‚Üì 2020-01-11... ‚úì (22/50)\n",
      "    ‚Üì 2020-01-16... ‚úì (23/50)\n",
      "    ‚Üì 2020-01-21... ‚úì (24/50)\n",
      "    ‚Üì 2020-01-26... ‚úì (25/50)\n",
      "    ‚Üì 2020-01-31... ‚úì (26/50)\n",
      "    ‚Üì 2020-02-10... ‚úì (27/50)\n",
      "    ‚Üì 2020-02-15... ‚úì (28/50)\n",
      "    ‚Üì 2020-03-01... ‚úì (29/50)\n",
      "    ‚Üì 2020-03-16... ‚úì (30/50)\n",
      "  2021: 40 images available\n",
      "    ‚Üì 2021-01-05... ‚úì (31/50)\n",
      "    ‚Üì 2021-01-10... ‚úì (32/50)\n",
      "    ‚Üì 2021-01-15... ‚úì (33/50)\n",
      "    ‚Üì 2021-01-20... ‚úì (34/50)\n",
      "    ‚Üì 2021-01-25... ‚úì (35/50)\n",
      "    ‚Üì 2021-01-30... ‚úì (36/50)\n",
      "    ‚Üì 2021-02-04... ‚úì (37/50)\n",
      "    ‚Üì 2021-02-09... ‚úì (38/50)\n",
      "    ‚Üì 2021-02-14... ‚úì (39/50)\n",
      "    ‚Üì 2021-02-24... ‚úì (40/50)\n",
      "  2022: 40 images available\n",
      "    ‚Üì 2022-01-05... ‚úì (41/50)\n",
      "    ‚Üì 2022-01-10... ‚úì (42/50)\n",
      "    ‚Üì 2022-01-20... ‚úì (43/50)\n",
      "    ‚Üì 2022-01-30... ‚úì (44/50)\n",
      "    ‚Üì 2022-02-04... ‚úì (45/50)\n",
      "    ‚Üì 2022-02-14... ‚úì (46/50)\n",
      "    ‚Üì 2022-02-19... ‚úì (47/50)\n",
      "    ‚Üì 2022-02-24... ‚úì (48/50)\n",
      "    ‚Üì 2022-03-01... ‚úì (49/50)\n",
      "    ‚Üì 2022-03-06... ‚úì (50/50)\n",
      "\n",
      "======================================================================\n",
      "DOWNLOAD COMPLETE\n",
      "======================================================================\n",
      "‚úì Downloaded: 50 images\n",
      "‚úó Failed: 0\n",
      "üìÅ Location: hasdeo_forest_dataset_rgb/rgb_images/\n",
      "\n",
      "‚úì Images are in standard PNG format and viewable!\n",
      "You can open them with any image viewer or photo app.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hasdeo Forest RGB Image Downloader - VIEWABLE VERSION\n",
    "Downloads RGB satellite imagery for Hasdeo Arand in standard viewable format.\n",
    "Images are saved as PNG with proper color scaling for visualization.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "OUTPUT_DIR = 'hasdeo_forest_dataset_rgb'\n",
    "NUM_IMAGES = 50  \n",
    "SCALE = 30  # 30m resolution for manageable file sizes\n",
    "MAX_CLOUD_COVER = 30  # Reduced for better quality images\n",
    "\n",
    "# Hasdeo Forest Area of Interest\n",
    "# Coordinates: [lon_min, lat_min, lon_max, lat_max]\n",
    "HASDEO_REGION = {\n",
    "    'Hasdeo_Arand_Zoomed': [82.75, 22.95, 82.85, 23.05]\n",
    "}\n",
    "\n",
    "# Year ranges for sampling\n",
    "YEAR_RANGES = [\n",
    "    ('2018-01-01', '2019-01-01'),\n",
    "    ('2019-01-01', '2020-01-01'),\n",
    "    ('2020-01-01', '2021-01-01'),\n",
    "    ('2021-01-01', '2022-01-01'),\n",
    "    ('2022-01-01', '2023-01-01'),\n",
    "    ('2023-01-01', '2024-01-01'),\n",
    "    ('2024-01-01', '2025-01-01'),\n",
    "]\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"‚úì Earth Engine initialized for project: {PROJECT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Initialization failed. Attempting authentication...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"‚úì Authentication successful. Earth Engine initialized.\")\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"Create output directory structure\"\"\"\n",
    "    Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/rgb_images\").mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/metadata\").mkdir(exist_ok=True)\n",
    "    print(f\"‚úì Created output directories in {OUTPUT_DIR}/\")\n",
    "\n",
    "def get_satellite_collection(start_date, end_date, roi, max_cloud_cover):\n",
    "    \"\"\"Get Sentinel-2 collection with cloud filtering\"\"\"\n",
    "    # Sentinel-2 Surface Reflectance with cloud masking\n",
    "    def maskS2clouds(image):\n",
    "        qa = image.select('QA60')\n",
    "        # Bits 10 and 11 are clouds and cirrus\n",
    "        cloudBitMask = 1 << 10\n",
    "        cirrusBitMask = 1 << 11\n",
    "        mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(\n",
    "            qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "        return image.updateMask(mask)\n",
    "    \n",
    "    sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover)) \\\n",
    "        .map(maskS2clouds)\n",
    "\n",
    "    s2_count = sentinel2.size().getInfo()\n",
    "    \n",
    "    if s2_count > 0:\n",
    "        return sentinel2, 'sentinel2'\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def download_rgb_image(image, region, filename):\n",
    "    \"\"\"Downloads RGB image in viewable PNG format\"\"\"\n",
    "    try:\n",
    "        # Select RGB bands (B4=Red, B3=Green, B2=Blue)\n",
    "        rgb = image.select(['B4', 'B3', 'B2'])\n",
    "        \n",
    "        # Normalize to 0-255 range for viewing\n",
    "        # Sentinel-2 values are 0-10000, we'll use 0-3000 as typical range\n",
    "        rgb_vis = rgb.visualize(\n",
    "            min=0,\n",
    "            max=3000,\n",
    "            bands=['B4', 'B3', 'B2']\n",
    "        )\n",
    "        \n",
    "        # Get thumbnail URL (this returns a viewable image)\n",
    "        url = rgb_vis.getThumbURL({\n",
    "            'region': region,\n",
    "            'dimensions': 1024,  # 1024x1024 pixels\n",
    "            'format': 'png'\n",
    "        })\n",
    "        \n",
    "        # Download and save as PNG\n",
    "        response = requests.get(url, timeout=300)\n",
    "        if response.status_code == 200:\n",
    "            # Save directly as PNG\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚úó HTTP Error {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"‚úó Error: {error_msg[:100]}...\")\n",
    "        return False\n",
    "\n",
    "def save_metadata(image, filename, region_name):\n",
    "    \"\"\"Save image metadata\"\"\"\n",
    "    try:\n",
    "        props = image.getInfo()['properties']\n",
    "        metadata_file = filename\n",
    "        \n",
    "        with open(metadata_file, 'w') as f:\n",
    "            f.write(f\"Region: {region_name}\\n\")\n",
    "            f.write(f\"Satellite: SENTINEL-2\\n\")\n",
    "            f.write(f\"Image Type: RGB (True Color)\\n\")\n",
    "            f.write(f\"Format: PNG (Viewable)\\n\")\n",
    "            \n",
    "            date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "            f.write(f\"Date: {date}\\n\")\n",
    "            f.write(f\"Cloud Cover: {props.get('CLOUDY_PIXEL_PERCENTAGE', 'N/A')}%\\n\")\n",
    "            f.write(f\"Product ID: {props.get('PRODUCT_ID', 'N/A')}\\n\")\n",
    "            f.write(f\"Bands: R=B4 (Red), G=B3 (Green), B=B2 (Blue)\\n\")\n",
    "            f.write(f\"Resolution: {SCALE}m\\n\")\n",
    "            f.write(f\"Processing: Cloud-masked, normalized to 0-255\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Metadata warning: {str(e)[:30]}\")\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "def main_hasdeo():\n",
    "    \"\"\"Main download function for Hasdeo Forest\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"HASDEO FOREST IMAGE DOWNLOADER - RGB VIEWABLE VERSION\")\n",
    "    print(f\"Targeting Central Hasdeo Region: {HASDEO_REGION['Hasdeo_Arand_Zoomed']}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    create_output_dirs()\n",
    "    \n",
    "    downloaded_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    print(f\"\\nTarget: {NUM_IMAGES} images (Max Cloud Cover: {MAX_CLOUD_COVER}%)\")\n",
    "    print(f\"Time periods: {len(YEAR_RANGES)}\")\n",
    "    print(f\"Resolution: {SCALE}m | Format: PNG (Viewable RGB)\\n\")\n",
    "    \n",
    "    region_name = 'Hasdeo_Arand_Zoomed'\n",
    "    coords = HASDEO_REGION[region_name]\n",
    "    roi = ee.Geometry.Rectangle(coords)\n",
    "\n",
    "    print(f\"üå≥ Starting Downloads for: {region_name}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Iterate through each year range\n",
    "    for start_date, end_date in YEAR_RANGES:\n",
    "        if downloaded_count >= NUM_IMAGES:\n",
    "            break\n",
    "        \n",
    "        # Get the satellite collection for the year\n",
    "        collection, satellite_type = get_satellite_collection(start_date, end_date, roi, MAX_CLOUD_COVER)\n",
    "        \n",
    "        if collection is None:\n",
    "            print(f\"  {start_date[:4]}: 0 images found\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            count = collection.size().getInfo()\n",
    "            if count == 0:\n",
    "                print(f\"  {start_date[:4]}: 0 images found\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"  {start_date[:4]}: {count} images available\")\n",
    "            \n",
    "            # Limit download per year\n",
    "            images_to_download = min(10, count, NUM_IMAGES - downloaded_count)\n",
    "            if images_to_download <= 0:\n",
    "                break\n",
    "                \n",
    "            images = collection.limit(images_to_download).toList(images_to_download)\n",
    "            \n",
    "            for i in range(images_to_download):\n",
    "                if downloaded_count >= NUM_IMAGES:\n",
    "                    break\n",
    "                    \n",
    "                image = ee.Image(images.get(i))\n",
    "                \n",
    "                # Get date\n",
    "                date_acquired = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                \n",
    "                # Filename construction (PNG format)\n",
    "                filename = f\"{OUTPUT_DIR}/rgb_images/{region_name}_{date_acquired}_RGB.png\"\n",
    "                metadata_filename = f\"{OUTPUT_DIR}/metadata/{region_name}_{date_acquired}_metadata.txt\"\n",
    "                \n",
    "                # Skip if exists\n",
    "                if os.path.exists(filename):\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"    ‚äô {date_acquired} (exists)\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"    ‚Üì {date_acquired}...\", end=' ')\n",
    "                \n",
    "                if download_rgb_image(image, roi, filename):\n",
    "                    save_metadata(image, metadata_filename, region_name)\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"‚úì ({downloaded_count}/{NUM_IMAGES})\")\n",
    "                else:\n",
    "                    failed_count += 1\n",
    "                \n",
    "                time.sleep(2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Error in collection processing: {str(e)[:50]}...\")\n",
    "            continue\n",
    "            \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"DOWNLOAD COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"‚úì Downloaded: {downloaded_count} images\")\n",
    "    print(f\"‚úó Failed: {failed_count}\")\n",
    "    print(f\"üìÅ Location: {OUTPUT_DIR}/rgb_images/\")\n",
    "    print(\"\\n‚úì Images are in standard PNG format and viewable!\")\n",
    "    print(\"You can open them with any image viewer or photo app.\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_hasdeo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14f471-c7a1-4308-a868-23338b1a726b",
   "metadata": {},
   "source": [
    "## 2. Kangaroo Island Black Summer Bushfire Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdc9e7e9-4202-4a65-9f0c-1530cd2fb5e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Earth Engine initialized for project: glacier-probe-model-475519\n",
      "================================================================================\n",
      "KANGAROO ISLAND BLACK SUMMER BUSHFIRE IMAGE DOWNLOADER\n",
      "Coordinates: [136.5344, -36.0867, 138.0, -35.5614]\n",
      "Fire Period: December 20, 2019 - February 6, 2020\n",
      "Coverage: 5 years pre-fire (2014-2019) + fire period + 5 years post-fire (2020-2024)\n",
      "================================================================================\n",
      "‚úì Created output directories in kangaroo_island_black_summer/\n",
      "\n",
      "Target: 100 images (Max Cloud Cover: 100%)\n",
      "Time periods: 12\n",
      "Resolution: 30m | Format: PNG (Viewable RGB)\n",
      "\n",
      "üî• Starting Downloads for: Kangaroo Island Black Summer\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE (2014): 0 images found\n",
      "  PRE-FIRE (2015): 0 images found\n",
      "  PRE-FIRE (2016): 0 images found\n",
      "  PRE-FIRE (2017): 4 images available\n",
      "    ‚Üì 2017-03-08... ‚úì (1/100)\n",
      "    ‚Üì 2017-07-21... ‚úì (2/100)\n",
      "    ‚äô 2017-07-21 (exists)\n",
      "    ‚Üì 2017-12-26... ‚úì (4/100)\n",
      "  PRE-FIRE (2018): 28 images available\n",
      "    ‚Üì 2018-02-06... ‚úì (5/100)\n",
      "    ‚äô 2018-02-06 (exists)\n",
      "    ‚Üì 2018-02-26... ‚úì (7/100)\n",
      "    ‚äô 2018-02-26 (exists)\n",
      "    ‚Üì 2018-03-16... ‚úì (9/100)\n",
      "    ‚Üì 2018-03-31... ‚úì (10/100)\n",
      "    ‚äô 2018-03-31 (exists)\n",
      "    ‚Üì 2018-04-07... ‚úì (12/100)\n",
      "  2019: 346 images available\n",
      "    ‚Üì 2019-01-02... ‚úì (13/100)\n",
      "    ‚äô 2019-01-02 (exists)\n",
      "    ‚Üì 2019-01-05... ‚úì (15/100)\n",
      "    ‚äô 2019-01-05 (exists)\n",
      "    ‚äô 2019-01-05 (exists)\n",
      "    ‚Üì 2019-01-07... ‚úì (18/100)\n",
      "    ‚äô 2019-01-07 (exists)\n",
      "    ‚Üì 2019-01-10... ‚úì (20/100)\n",
      "  DURING FIRE (Dec 20, 2019 - Feb 6, 2020): 50 images available\n",
      "    ‚Üì 2019-12-21... ‚úì (21/100)\n",
      "    ‚äô 2019-12-21 (exists)\n",
      "    ‚äô 2019-12-21 (exists)\n",
      "    ‚Üì 2019-12-23... ‚úì (24/100)\n",
      "    ‚äô 2019-12-23 (exists)\n",
      "    ‚Üì 2019-12-26... ‚úì (26/100)\n",
      "    ‚äô 2019-12-26 (exists)\n",
      "    ‚äô 2019-12-26 (exists)\n",
      "    ‚Üì 2019-12-28... ‚úì (29/100)\n",
      "    ‚äô 2019-12-28 (exists)\n",
      "    ‚Üì 2019-12-31... ‚úì (31/100)\n",
      "    ‚äô 2019-12-31 (exists)\n",
      "    ‚äô 2019-12-31 (exists)\n",
      "    ‚Üì 2020-01-02... ‚úì (34/100)\n",
      "    ‚äô 2020-01-02 (exists)\n",
      "    ‚Üì 2020-01-05... ‚úì (36/100)\n",
      "    ‚äô 2020-01-05 (exists)\n",
      "    ‚Üì 2020-01-07... ‚úì (38/100)\n",
      "    ‚äô 2020-01-07 (exists)\n",
      "    ‚Üì 2020-01-10... ‚úì (40/100)\n",
      "  POST-FIRE RECOVERY (+0 years - 2020): 321 images available\n",
      "    ‚Üì 2020-02-09... ‚úì (41/100)\n",
      "    ‚äô 2020-02-09 (exists)\n",
      "    ‚äô 2020-02-09 (exists)\n",
      "    ‚Üì 2020-02-11... ‚úì (44/100)\n",
      "    ‚äô 2020-02-11 (exists)\n",
      "    ‚Üì 2020-02-14... ‚úì (46/100)\n",
      "    ‚äô 2020-02-14 (exists)\n",
      "    ‚äô 2020-02-14 (exists)\n",
      "  POST-FIRE RECOVERY (+1 years - 2021): 367 images available\n",
      "    ‚Üì 2021-01-01... ‚úì (49/100)\n",
      "    ‚äô 2021-01-01 (exists)\n",
      "    ‚Üì 2021-01-04... ‚úì (51/100)\n",
      "    ‚äô 2021-01-04 (exists)\n",
      "    ‚äô 2021-01-04 (exists)\n",
      "    ‚Üì 2021-01-06... ‚úì (54/100)\n",
      "    ‚äô 2021-01-06 (exists)\n",
      "    ‚Üì 2021-01-09... ‚úì (56/100)\n",
      "  POST-FIRE RECOVERY (+2 years - 2022): 355 images available\n",
      "    ‚Üì 2022-01-01... ‚úì (57/100)\n",
      "    ‚äô 2022-01-01 (exists)\n",
      "    ‚Üì 2022-01-04... ‚úì (59/100)\n",
      "    ‚äô 2022-01-04 (exists)\n",
      "    ‚äô 2022-01-04 (exists)\n",
      "    ‚Üì 2022-01-06... ‚úì (62/100)\n",
      "    ‚äô 2022-01-06 (exists)\n",
      "    ‚Üì 2022-01-09... ‚úì (64/100)\n",
      "  POST-FIRE RECOVERY (+3 years - 2023): 365 images available\n",
      "    ‚Üì 2023-01-01... ‚úì (65/100)\n",
      "    ‚äô 2023-01-01 (exists)\n",
      "    ‚Üì 2023-01-04... ‚úì (67/100)\n",
      "    ‚äô 2023-01-04 (exists)\n",
      "    ‚äô 2023-01-04 (exists)\n",
      "    ‚Üì 2023-01-06... ‚úì (70/100)\n",
      "    ‚äô 2023-01-06 (exists)\n",
      "    ‚Üì 2023-01-09... ‚úì (72/100)\n",
      "  POST-FIRE RECOVERY (+4 years - 2024): 371 images available\n",
      "    ‚Üì 2024-01-01... ‚úì (73/100)\n",
      "    ‚äô 2024-01-01 (exists)\n",
      "    ‚Üì 2024-01-04... ‚úì (75/100)\n",
      "    ‚äô 2024-01-04 (exists)\n",
      "    ‚äô 2024-01-04 (exists)\n",
      "    ‚Üì 2024-01-09... ‚úì (78/100)\n",
      "    ‚äô 2024-01-09 (exists)\n",
      "    ‚äô 2024-01-09 (exists)\n",
      "\n",
      "================================================================================\n",
      "DOWNLOAD COMPLETE - KANGAROO ISLAND BLACK SUMMER DATASET\n",
      "================================================================================\n",
      "‚úì Downloaded: 80 images\n",
      "‚úó Failed: 0\n",
      "üìÅ Location: kangaroo_island_black_summer/rgb_images/\n",
      "\n",
      "üìä Dataset Coverage:\n",
      "   ‚Ä¢ Pre-fire baseline: 2014-2019 (5 years)\n",
      "   ‚Ä¢ Active fire period: Dec 20, 2019 - Feb 6, 2020\n",
      "   ‚Ä¢ Post-fire recovery: 2020-2024 (5 years)\n",
      "   ‚Ä¢ Area burned: ~211,500 hectares (48% of island)\n",
      "\n",
      "‚úì Images are in standard PNG format and viewable!\n",
      "You can open them with any image viewer or photo app.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Kangaroo Island Black Summer Bushfire Image Downloader\n",
    "Downloads RGB satellite imagery for Kangaroo Island, South Australia\n",
    "Covering the 2019-20 Black Summer bushfire period and recovery\n",
    "Images are saved as PNG with proper color scaling for visualization.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "OUTPUT_DIR = 'kangaroo_island_black_summer'\n",
    "NUM_IMAGES = 100  # More images to capture pre-fire, during, and post-fire periods\n",
    "SCALE = 30  # 30m resolution for manageable file sizes\n",
    "MAX_CLOUD_COVER = 100  # Allow ALL images including heavy smoke/clouds\n",
    "\n",
    "# Kangaroo Island Area of Interest - Black Summer Fire Zone\n",
    "# Coordinates converted from DMS to decimal degrees:\n",
    "# Latitude: 35¬∞33'41\"S to 36¬∞05'12\"S = -35.5614 to -36.0867\n",
    "# Longitude: 136¬∞32'04\"E to 138¬∞00'00\"E = 136.5344 to 138.0000\n",
    "KANGAROO_ISLAND_REGION = {\n",
    "    'Kangaroo_Island_Fire_Zone': [136.5344, -36.0867, 138.0000, -35.5614]\n",
    "}\n",
    "\n",
    "# Black Summer bushfires on Kangaroo Island:\n",
    "# - Started: December 20, 2019 (lightning strikes)\n",
    "# - Major fires: December 30, 2019 - February 6, 2020\n",
    "# - Declared safe: February 6, 2020\n",
    "# Year ranges: 5 years before (2014-2019) and 5 years after (2020-2025)\n",
    "YEAR_RANGES = [\n",
    "    # Pre-fire period (5 years before)\n",
    "    ('2014-01-01', '2014-12-31'),\n",
    "    ('2015-01-01', '2015-12-31'),\n",
    "    ('2016-01-01', '2016-12-31'),\n",
    "    ('2017-01-01', '2017-12-31'),\n",
    "    ('2018-01-01', '2018-12-31'),\n",
    "    # Critical fire year\n",
    "    ('2019-01-01', '2019-12-19'),  # Pre-fire 2019\n",
    "    ('2019-12-20', '2020-02-06'),  # During fire (Dec 20, 2019 - Feb 6, 2020)\n",
    "    ('2020-02-07', '2020-12-31'),  # Post-fire recovery 2020\n",
    "    # Post-fire recovery period (4 more years)\n",
    "    ('2021-01-01', '2021-12-31'),\n",
    "    ('2022-01-01', '2022-12-31'),\n",
    "    ('2023-01-01', '2023-12-31'),\n",
    "    ('2024-01-01', '2024-12-31'),\n",
    "]\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"‚úì Earth Engine initialized for project: {PROJECT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Initialization failed. Attempting authentication...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"‚úì Authentication successful. Earth Engine initialized.\")\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"Create output directory structure\"\"\"\n",
    "    Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/rgb_images\").mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/metadata\").mkdir(exist_ok=True)\n",
    "    print(f\"‚úì Created output directories in {OUTPUT_DIR}/\")\n",
    "\n",
    "def get_satellite_collection(start_date, end_date, roi, max_cloud_cover):\n",
    "    \"\"\"Get Sentinel-2 collection WITHOUT cloud masking to preserve smoke/fire effects\"\"\"\n",
    "    # NO CLOUD MASKING - We want to see smoke, clouds, and fire effects!\n",
    "    sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "\n",
    "    s2_count = sentinel2.size().getInfo()\n",
    "    \n",
    "    if s2_count > 0:\n",
    "        return sentinel2, 'sentinel2'\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def download_rgb_image(image, region, filename):\n",
    "    \"\"\"Downloads RGB image in viewable PNG format\"\"\"\n",
    "    try:\n",
    "        # Select RGB bands (B4=Red, B3=Green, B2=Blue)\n",
    "        rgb = image.select(['B4', 'B3', 'B2'])\n",
    "        \n",
    "        # Normalize to 0-255 range for viewing\n",
    "        # Sentinel-2 values are 0-10000, we'll use 0-3000 as typical range\n",
    "        rgb_vis = rgb.visualize(\n",
    "            min=0,\n",
    "            max=3000,\n",
    "            bands=['B4', 'B3', 'B2']\n",
    "        )\n",
    "        \n",
    "        # Get thumbnail URL (this returns a viewable image)\n",
    "        url = rgb_vis.getThumbURL({\n",
    "            'region': region,\n",
    "            'dimensions': 2048,  # Higher resolution for large area (2048x2048)\n",
    "            'format': 'png'\n",
    "        })\n",
    "        \n",
    "        # Download and save as PNG\n",
    "        response = requests.get(url, timeout=300)\n",
    "        if response.status_code == 200:\n",
    "            # Save directly as PNG\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚úó HTTP Error {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"‚úó Error: {error_msg[:100]}...\")\n",
    "        return False\n",
    "\n",
    "def save_metadata(image, filename, region_name, period_label):\n",
    "    \"\"\"Save image metadata\"\"\"\n",
    "    try:\n",
    "        props = image.getInfo()['properties']\n",
    "        metadata_file = filename\n",
    "        \n",
    "        with open(metadata_file, 'w') as f:\n",
    "            f.write(f\"Region: {region_name}\\n\")\n",
    "            f.write(f\"Location: Kangaroo Island, South Australia\\n\")\n",
    "            f.write(f\"Event: Black Summer Bushfires (2019-20)\\n\")\n",
    "            f.write(f\"Period: {period_label}\\n\")\n",
    "            f.write(f\"Satellite: SENTINEL-2\\n\")\n",
    "            f.write(f\"Image Type: RGB (True Color)\\n\")\n",
    "            f.write(f\"Format: PNG (Viewable)\\n\")\n",
    "            \n",
    "            date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "            f.write(f\"Date: {date}\\n\")\n",
    "            f.write(f\"Cloud Cover: {props.get('CLOUDY_PIXEL_PERCENTAGE', 'N/A')}%\\n\")\n",
    "            f.write(f\"Product ID: {props.get('PRODUCT_ID', 'N/A')}\\n\")\n",
    "            f.write(f\"Bands: R=B4 (Red), G=B3 (Green), B=B2 (Blue)\\n\")\n",
    "            f.write(f\"Resolution: {SCALE}m\\n\")\n",
    "            f.write(f\"Processing: NO cloud masking - smoke and fire effects preserved\\n\")\n",
    "            f.write(f\"\\nContext: Area burned ~211,500 ha (48% of island)\\n\")\n",
    "            f.write(f\"Fire Period: Dec 20, 2019 - Feb 6, 2020\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Metadata warning: {str(e)[:30]}\")\n",
    "\n",
    "def get_period_label(start_date, end_date):\n",
    "    \"\"\"Get descriptive label for the time period\"\"\"\n",
    "    if '2019-12-20' in start_date and '2020-02-06' in end_date:\n",
    "        return \"DURING FIRE (Dec 20, 2019 - Feb 6, 2020)\"\n",
    "    elif int(start_date[:4]) < 2019 or (start_date[:4] == '2019' and '12-19' in start_date):\n",
    "        return f\"PRE-FIRE ({start_date[:4]})\"\n",
    "    elif int(start_date[:4]) >= 2020:\n",
    "        years_after = int(start_date[:4]) - 2020\n",
    "        return f\"POST-FIRE RECOVERY (+{years_after} years - {start_date[:4]})\"\n",
    "    return start_date[:4]\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "def main_kangaroo_island():\n",
    "    \"\"\"Main download function for Kangaroo Island Black Summer\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"KANGAROO ISLAND BLACK SUMMER BUSHFIRE IMAGE DOWNLOADER\")\n",
    "    print(f\"Coordinates: {KANGAROO_ISLAND_REGION['Kangaroo_Island_Fire_Zone']}\")\n",
    "    print(\"Fire Period: December 20, 2019 - February 6, 2020\")\n",
    "    print(\"Coverage: 5 years pre-fire (2014-2019) + fire period + 5 years post-fire (2020-2024)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    create_output_dirs()\n",
    "    \n",
    "    downloaded_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    print(f\"\\nTarget: {NUM_IMAGES} images (Max Cloud Cover: {MAX_CLOUD_COVER}%)\")\n",
    "    print(f\"Time periods: {len(YEAR_RANGES)}\")\n",
    "    print(f\"Resolution: {SCALE}m | Format: PNG (Viewable RGB)\\n\")\n",
    "    \n",
    "    region_name = 'Kangaroo_Island_Fire_Zone'\n",
    "    coords = KANGAROO_ISLAND_REGION[region_name]\n",
    "    roi = ee.Geometry.Rectangle(coords)\n",
    "\n",
    "    print(f\"üî• Starting Downloads for: Kangaroo Island Black Summer\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Iterate through each year range\n",
    "    for start_date, end_date in YEAR_RANGES:\n",
    "        if downloaded_count >= NUM_IMAGES:\n",
    "            break\n",
    "        \n",
    "        period_label = get_period_label(start_date, end_date)\n",
    "        \n",
    "        # Get the satellite collection for the period\n",
    "        collection, satellite_type = get_satellite_collection(start_date, end_date, roi, MAX_CLOUD_COVER)\n",
    "        \n",
    "        if collection is None:\n",
    "            print(f\"  {period_label}: 0 images found\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            count = collection.size().getInfo()\n",
    "            if count == 0:\n",
    "                print(f\"  {period_label}: 0 images found\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"  {period_label}: {count} images available\")\n",
    "            \n",
    "            # Adjust number of images per period\n",
    "            # More images during fire period, fewer for other years\n",
    "            if 'DURING FIRE' in period_label:\n",
    "                images_per_period = min(20, count, NUM_IMAGES - downloaded_count)\n",
    "            else:\n",
    "                images_per_period = min(8, count, NUM_IMAGES - downloaded_count)\n",
    "                \n",
    "            if images_per_period <= 0:\n",
    "                break\n",
    "                \n",
    "            images = collection.limit(images_per_period).toList(images_per_period)\n",
    "            \n",
    "            for i in range(images_per_period):\n",
    "                if downloaded_count >= NUM_IMAGES:\n",
    "                    break\n",
    "                    \n",
    "                image = ee.Image(images.get(i))\n",
    "                \n",
    "                # Get date\n",
    "                date_acquired = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                \n",
    "                # Filename construction (PNG format)\n",
    "                period_prefix = period_label.split('(')[0].strip().replace(' ', '_').replace('-', '')\n",
    "                filename = f\"{OUTPUT_DIR}/rgb_images/KI_{date_acquired}_{period_prefix}_RGB.png\"\n",
    "                metadata_filename = f\"{OUTPUT_DIR}/metadata/KI_{date_acquired}_{period_prefix}_metadata.txt\"\n",
    "                \n",
    "                # Skip if exists\n",
    "                if os.path.exists(filename):\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"    ‚äô {date_acquired} (exists)\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"    ‚Üì {date_acquired}...\", end=' ')\n",
    "                \n",
    "                if download_rgb_image(image, roi, filename):\n",
    "                    save_metadata(image, metadata_filename, region_name, period_label)\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"‚úì ({downloaded_count}/{NUM_IMAGES})\")\n",
    "                else:\n",
    "                    failed_count += 1\n",
    "                \n",
    "                time.sleep(2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Error in collection processing: {str(e)[:50]}...\")\n",
    "            continue\n",
    "            \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DOWNLOAD COMPLETE - KANGAROO ISLAND BLACK SUMMER DATASET\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"‚úì Downloaded: {downloaded_count} images\")\n",
    "    print(f\"‚úó Failed: {failed_count}\")\n",
    "    print(f\"üìÅ Location: {OUTPUT_DIR}/rgb_images/\")\n",
    "    print(f\"\\nüìä Dataset Coverage:\")\n",
    "    print(f\"   ‚Ä¢ Pre-fire baseline: 2014-2019 (5 years)\")\n",
    "    print(f\"   ‚Ä¢ Active fire period: Dec 20, 2019 - Feb 6, 2020\")\n",
    "    print(f\"   ‚Ä¢ Post-fire recovery: 2020-2024 (5 years)\")\n",
    "    print(f\"   ‚Ä¢ Area burned: ~211,500 hectares (48% of island)\")\n",
    "    print(f\"\\n‚úì Images are in standard PNG format and viewable!\")\n",
    "    print(\"You can open them with any image viewer or photo app.\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_kangaroo_island()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970422d-6e15-4911-921f-487f05dc3532",
   "metadata": {},
   "source": [
    "## 3. Greater Sydney Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84ebeed6-fbd2-4c21-93eb-d99fac592431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Earth Engine initialized for project: glacier-probe-model-475519\n",
      "================================================================================\n",
      "üá¶üá∫ GREATER SYDNEY BLUE MOUNTAINS FRINGE IMAGE DOWNLOADER\n",
      "Multiple Sub-Regions for Complete Coverage\n",
      "================================================================================\n",
      "üìç Regions: 5\n",
      "   ‚Ä¢ Blue_Mts_Katoomba: [150.25, -33.75, 150.35, -33.65]\n",
      "   ‚Ä¢ Blue_Mts_Wentworth_Falls: [150.35, -33.75, 150.45, -33.65]\n",
      "   ‚Ä¢ Warragamba_Dam_North: [150.55, -33.95, 150.65, -33.85]\n",
      "   ‚Ä¢ Warragamba_Dam_South: [150.55, -34.05, 150.65, -33.95]\n",
      "   ‚Ä¢ Penrith_Urban_Edge: [150.65, -33.8, 150.75, -33.7]\n",
      "üî• Event: Black Summer Bushfires (2019-2020)\n",
      "üåµ Context: Prolonged drought + catastrophic fire + urban expansion\n",
      "üìä Research: Bushfire, Drought, Regrowth, Deforestation\n",
      "================================================================================\n",
      "‚úì Created output directories in sydney_blue_mountains_fringe_rgb/\n",
      "\n",
      "Target: 75 images total (~15 per region)\n",
      "Time periods: 7\n",
      "Resolution: 30m | Format: PNG (Viewable RGB)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üå≥ Processing Region: Blue_Mts_Katoomba\n",
      "üìç Coordinates: [150.25, -33.75, 150.35, -33.65]\n",
      "üéØ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 12 images available\n",
      "    ‚Üì 2018-02-14... ‚úì (1/15)\n",
      "    ‚Üì 2018-03-11... ‚úì (2/15)\n",
      "    ‚äô 2018-03-11 (exists)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 140 images available\n",
      "    ‚Üì 2019-06-04... ‚úì (4/15)\n",
      "    ‚äô 2019-06-04 (exists)\n",
      "    ‚Üì 2019-06-09... ‚úì (6/15)\n",
      "    ‚äô 2019-06-09 (exists)\n",
      "    ‚Üì 2019-06-14... ‚úì (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 143 images available\n",
      "    ‚Üì 2020-06-03... ‚úì (9/15)\n",
      "    ‚äô 2020-06-03 (exists)\n",
      "    ‚Üì 2020-06-08... ‚úì (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 141 images available\n",
      "    ‚Üì 2021-06-03... ‚úì (12/15)\n",
      "    ‚äô 2021-06-03 (exists)\n",
      "    ‚Üì 2021-06-08... ‚úì (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 146 images available\n",
      "    ‚Üì 2022-06-03... ‚úì (15/15)\n",
      "\n",
      "‚úì Blue_Mts_Katoomba: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "üå≥ Processing Region: Blue_Mts_Wentworth_Falls\n",
      "üìç Coordinates: [150.35, -33.75, 150.45, -33.65]\n",
      "üéØ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    ‚Üì 2018-03-11... ‚úì (1/15)\n",
      "    ‚Üì 2018-06-04... ‚úì (2/15)\n",
      "    ‚Üì 2018-12-16... ‚úì (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    ‚Üì 2019-06-04... ‚úì (4/15)\n",
      "    ‚Üì 2019-06-09... ‚úì (5/15)\n",
      "    ‚Üì 2019-06-14... ‚úì (6/15)\n",
      "    ‚Üì 2019-06-19... ‚úì (7/15)\n",
      "    ‚Üì 2019-06-24... ‚úì (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    ‚Üì 2020-06-03... ‚úì (9/15)\n",
      "    ‚Üì 2020-06-08... ‚úì (10/15)\n",
      "    ‚Üì 2020-06-13... ‚úì (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    ‚Üì 2021-06-03... ‚úì (12/15)\n",
      "    ‚Üì 2021-06-08... ‚úì (13/15)\n",
      "    ‚Üì 2021-06-13... ‚úì (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    ‚Üì 2022-06-03... ‚úì (15/15)\n",
      "\n",
      "‚úì Blue_Mts_Wentworth_Falls: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "üå≥ Processing Region: Warragamba_Dam_North\n",
      "üìç Coordinates: [150.55, -33.95, 150.65, -33.85]\n",
      "üéØ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    ‚Üì 2018-03-11... ‚úì (1/15)\n",
      "    ‚Üì 2018-06-04... ‚úì (2/15)\n",
      "    ‚Üì 2018-12-16... ‚úì (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    ‚Üì 2019-06-04... ‚úì (4/15)\n",
      "    ‚Üì 2019-06-09... ‚úì (5/15)\n",
      "    ‚Üì 2019-06-14... ‚úì (6/15)\n",
      "    ‚Üì 2019-06-19... ‚úì (7/15)\n",
      "    ‚Üì 2019-06-24... ‚úì (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    ‚Üì 2020-06-03... ‚úì (9/15)\n",
      "    ‚Üì 2020-06-08... ‚úì (10/15)\n",
      "    ‚Üì 2020-06-13... ‚úì (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    ‚Üì 2021-06-03... ‚úì (12/15)\n",
      "    ‚Üì 2021-06-08... ‚úì (13/15)\n",
      "    ‚Üì 2021-06-13... ‚úì (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    ‚Üì 2022-06-03... ‚úì (15/15)\n",
      "\n",
      "‚úì Warragamba_Dam_North: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "üå≥ Processing Region: Warragamba_Dam_South\n",
      "üìç Coordinates: [150.55, -34.05, 150.65, -33.95]\n",
      "üéØ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    ‚Üì 2018-03-11... ‚úì (1/15)\n",
      "    ‚Üì 2018-06-04... ‚úì (2/15)\n",
      "    ‚Üì 2018-12-16... ‚úì (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    ‚Üì 2019-06-04... ‚úì (4/15)\n",
      "    ‚Üì 2019-06-09... ‚úì (5/15)\n",
      "    ‚Üì 2019-06-14... ‚úì (6/15)\n",
      "    ‚Üì 2019-06-19... ‚úì (7/15)\n",
      "    ‚Üì 2019-06-24... ‚úì (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    ‚Üì 2020-06-03... ‚úì (9/15)\n",
      "    ‚Üì 2020-06-08... ‚úì (10/15)\n",
      "    ‚Üì 2020-06-13... ‚úì (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    ‚Üì 2021-06-03... ‚úì (12/15)\n",
      "    ‚Üì 2021-06-08... ‚úì (13/15)\n",
      "    ‚Üì 2021-06-13... ‚úì (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    ‚Üì 2022-06-03... ‚úì (15/15)\n",
      "\n",
      "‚úì Warragamba_Dam_South: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "üå≥ Processing Region: Penrith_Urban_Edge\n",
      "üìç Coordinates: [150.65, -33.8, 150.75, -33.7]\n",
      "üéØ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    ‚Üì 2018-03-11... ‚úì (1/15)\n",
      "    ‚Üì 2018-06-04... ‚úì (2/15)\n",
      "    ‚Üì 2018-12-16... ‚úì (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    ‚Üì 2019-06-04... ‚úì (4/15)\n",
      "    ‚Üì 2019-06-09... ‚úì (5/15)\n",
      "    ‚Üì 2019-06-14... ‚úì (6/15)\n",
      "    ‚Üì 2019-06-19... ‚úì (7/15)\n",
      "    ‚Üì 2019-06-24... ‚úì (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    ‚Üì 2020-06-03... ‚úì (9/15)\n",
      "    ‚Üì 2020-06-08... ‚úì (10/15)\n",
      "    ‚Üì 2020-06-13... ‚úì (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    ‚Üì 2021-06-03... ‚úì (12/15)\n",
      "    ‚Üì 2021-06-08... ‚úì (13/15)\n",
      "    ‚Üì 2021-06-13... ‚úì (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    ‚Üì 2022-06-03... ‚úì (15/15)\n",
      "\n",
      "‚úì Penrith_Urban_Edge: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "DOWNLOAD COMPLETE - SYDNEY BLUE MOUNTAINS MULTI-REGION DATASET\n",
      "================================================================================\n",
      "‚úì Total Downloaded: 75/75 images\n",
      "‚úó Total Failed: 0\n",
      "üìÅ Location: sydney_blue_mountains_fringe_rgb/rgb_images/\n",
      "\n",
      "üìä Dataset Coverage:\n",
      "   ‚Ä¢ Pre-fire baseline: 2018\n",
      "   ‚Ä¢ Drought & Black Summer fires: 2019-2020\n",
      "   ‚Ä¢ Post-fire recovery: 2020-2021\n",
      "   ‚Ä¢ Long-term monitoring: 2021-2025\n",
      "\n",
      "üó∫Ô∏è Sub-Regions Captured:\n",
      "   ‚Ä¢ Blue_Mts_Katoomba\n",
      "   ‚Ä¢ Blue_Mts_Wentworth_Falls\n",
      "   ‚Ä¢ Warragamba_Dam_North\n",
      "   ‚Ä¢ Warragamba_Dam_South\n",
      "   ‚Ä¢ Penrith_Urban_Edge\n",
      "\n",
      "üî¨ Recommended Analysis Indices:\n",
      "   ‚Ä¢ NBR (Normalized Burn Ratio): B8-B12 / B8+B12\n",
      "     ‚Üí Fire severity mapping, burn scar detection\n",
      "   ‚Ä¢ NDVI (Vegetation Index): B8-B4 / B8+B4\n",
      "     ‚Üí Vegetation health, regrowth monitoring\n",
      "   ‚Ä¢ EVI (Enhanced Vegetation): 2.5*(B8-B4) / (B8+6*B4-7.5*B2+1)\n",
      "     ‚Üí Drought stress, canopy density\n",
      "   ‚Ä¢ NDMI (Moisture Index): B8-B11 / B8+B11\n",
      "     ‚Üí Water stress, drought impact\n",
      "   ‚Ä¢ NDWI (Water Index): B3-B8 / B3+B8\n",
      "     ‚Üí Drought severity, water availability\n",
      "\n",
      "‚úì Images are in standard PNG format and viewable!\n",
      "All smoke, fire, and atmospheric effects are preserved.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Greater Sydney Blue Mountains Fringe Satellite Image Downloader\n",
    "Downloads RGB satellite imagery for the Blue Mountains/Warragamba Dam Catchment Area\n",
    "Captures: Bushfire (Black Summer 2019-20), Drought, Regrowth, and Deforestation\n",
    "Images are saved as PNG with proper color scaling for visualization.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# --- CONFIGURATION (MODIFIED for Sydney Blue Mountains Fringe) ---\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "OUTPUT_DIR = 'sydney_blue_mountains_fringe_rgb'\n",
    "NUM_IMAGES = 75  # 15 images per sub-region\n",
    "SCALE = 30  # Increased to 30m to ensure successful downloads\n",
    "MAX_CLOUD_COVER = 100  # Allow all images including smoke/clouds during fires\n",
    "\n",
    "# Greater Sydney Blue Mountains Fringe - Multiple Sub-Regions\n",
    "# Multiple smaller regions to ensure visible imagery capture\n",
    "# Coordinates: [lon_min, lat_min, lon_max, lat_max]\n",
    "SYDNEY_REGIONS = {\n",
    "    'Blue_Mts_Katoomba': [150.25, -33.75, 150.35, -33.65],  # Katoomba/Three Sisters area\n",
    "    'Blue_Mts_Wentworth_Falls': [150.35, -33.75, 150.45, -33.65],  # Wentworth Falls\n",
    "    'Warragamba_Dam_North': [150.55, -33.95, 150.65, -33.85],  # North of dam\n",
    "    'Warragamba_Dam_South': [150.55, -34.05, 150.65, -33.95],  # South of dam\n",
    "    'Penrith_Urban_Edge': [150.65, -33.80, 150.75, -33.70],  # Urban fringe\n",
    "}\n",
    "\n",
    "# Date ranges specifically targeting the Black Summer event and recovery/drought periods\n",
    "YEAR_RANGES = [\n",
    "    # Pre-fire/drought baseline\n",
    "    ('2018-01-01', '2019-01-01'), \n",
    "    # Peak drought and fire period (Black Summer)\n",
    "    ('2019-06-01', '2020-06-01'), \n",
    "    # Immediate post-fire and start of regrowth\n",
    "    ('2020-06-01', '2021-06-01'), \n",
    "    # Continued recovery and expansion monitoring\n",
    "    ('2021-06-01', '2022-06-01'),\n",
    "    ('2022-06-01', '2023-06-01'),\n",
    "    ('2023-06-01', '2024-06-01'),\n",
    "    ('2024-06-01', '2025-06-01'),\n",
    "]\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"‚úì Earth Engine initialized for project: {PROJECT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Initialization failed. Attempting authentication...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"‚úì Authentication successful. Earth Engine initialized.\")\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"Create output directory structure\"\"\"\n",
    "    Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/rgb_images\").mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/metadata\").mkdir(exist_ok=True)\n",
    "    print(f\"‚úì Created output directories in {OUTPUT_DIR}/\")\n",
    "\n",
    "def get_satellite_collection(start_date, end_date, roi, max_cloud_cover):\n",
    "    \"\"\"Get Sentinel-2 collection WITHOUT cloud masking to preserve all effects\"\"\"\n",
    "    sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "\n",
    "    s2_count = sentinel2.size().getInfo()\n",
    "    \n",
    "    if s2_count > 0:\n",
    "        return sentinel2, 'sentinel2'\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def download_rgb_image(image, region, filename):\n",
    "    \"\"\"Downloads RGB image in viewable PNG format\"\"\"\n",
    "    try:\n",
    "        # Select RGB bands (B4=Red, B3=Green, B2=Blue)\n",
    "        rgb = image.select(['B4', 'B3', 'B2'])\n",
    "        \n",
    "        # Normalize to 0-255 range for viewing\n",
    "        rgb_vis = rgb.visualize(\n",
    "            min=0,\n",
    "            max=3000,\n",
    "            bands=['B4', 'B3', 'B2']\n",
    "        )\n",
    "        \n",
    "        # Get thumbnail URL with adjusted dimensions\n",
    "        url = rgb_vis.getThumbURL({\n",
    "            'region': region,\n",
    "            'dimensions': 512,  # Reduced for better compatibility\n",
    "            'format': 'png'\n",
    "        })\n",
    "        \n",
    "        # Download and save as PNG\n",
    "        response = requests.get(url, timeout=300)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚úó HTTP Error {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"‚úó Error: {error_msg[:100]}...\")\n",
    "        return False\n",
    "\n",
    "def save_metadata(image, filename, region_name, period_label):\n",
    "    \"\"\"Save image metadata\"\"\"\n",
    "    try:\n",
    "        props = image.getInfo()['properties']\n",
    "        metadata_file = filename\n",
    "        \n",
    "        with open(metadata_file, 'w') as f:\n",
    "            f.write(f\"Region: {region_name}\\n\")\n",
    "            f.write(f\"Location: Greater Sydney - Blue Mountains Fringe & Warragamba Catchment\\n\")\n",
    "            f.write(f\"Research Focus: Bushfire, Drought, Regrowth, Deforestation\\n\")\n",
    "            f.write(f\"Period: {period_label}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Satellite: SENTINEL-2\\n\")\n",
    "            f.write(f\"Image Type: RGB (True Color)\\n\")\n",
    "            f.write(f\"Format: PNG (Viewable)\\n\")\n",
    "            \n",
    "            date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "            f.write(f\"Date: {date}\\n\")\n",
    "            f.write(f\"Cloud Cover: {props.get('CLOUDY_PIXEL_PERCENTAGE', 'N/A')}%\\n\")\n",
    "            f.write(f\"Product ID: {props.get('PRODUCT_ID', 'N/A')}\\n\")\n",
    "            f.write(f\"Bands: R=B4 (Red), G=B3 (Green), B=B2 (Blue)\\n\")\n",
    "            f.write(f\"Resolution: {SCALE}m\\n\")\n",
    "            f.write(f\"Processing: NO cloud masking - smoke and fire effects preserved\\n\")\n",
    "            \n",
    "            f.write(f\"\\n=== RESEARCH CONTEXT ===\\n\")\n",
    "            f.write(f\"Black Summer Fires: 2019-2020\\n\")\n",
    "            f.write(f\"Key Indices for Analysis:\\n\")\n",
    "            f.write(f\"  ‚Ä¢ NBR (Normalized Burn Ratio): Fire severity\\n\")\n",
    "            f.write(f\"  ‚Ä¢ NDVI (Normalized Difference Vegetation Index): Vegetation health/regrowth\\n\")\n",
    "            f.write(f\"  ‚Ä¢ EVI (Enhanced Vegetation Index): Drought impact\\n\")\n",
    "            f.write(f\"  ‚Ä¢ NDMI (Normalized Difference Moisture Index): Water stress\\n\")\n",
    "            f.write(f\"  ‚Ä¢ NDWI (Normalized Difference Water Index): Drought monitoring\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Metadata warning: {str(e)[:30]}\")\n",
    "\n",
    "def get_period_label(start_date, end_date):\n",
    "    \"\"\"Get descriptive label for the time period\"\"\"\n",
    "    if '2018' in start_date:\n",
    "        return \"PRE-FIRE BASELINE (2018)\"\n",
    "    elif '2019-06' in start_date and '2020-06' in end_date:\n",
    "        return \"DROUGHT & BLACK SUMMER FIRES (2019-2020)\"\n",
    "    elif '2020-06' in start_date and '2021' in end_date:\n",
    "        return \"IMMEDIATE POST-FIRE RECOVERY (2020-2021)\"\n",
    "    elif '2021' in start_date:\n",
    "        return f\"POST-FIRE RECOVERY & MONITORING ({start_date[:4]}-{end_date[:4]})\"\n",
    "    elif '2022' in start_date:\n",
    "        return f\"REGROWTH & DEFORESTATION MONITORING ({start_date[:4]}-{end_date[:4]})\"\n",
    "    elif '2023' in start_date or '2024' in start_date:\n",
    "        return f\"LONG-TERM RECOVERY ({start_date[:4]}-{end_date[:4]})\"\n",
    "    return f\"{start_date[:4]}-{end_date[:4]}\"\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "def main_sydney():\n",
    "    \"\"\"Main download function for Sydney Blue Mountains Fringe - Multiple Regions\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üá¶üá∫ GREATER SYDNEY BLUE MOUNTAINS FRINGE IMAGE DOWNLOADER\")\n",
    "    print(\"Multiple Sub-Regions for Complete Coverage\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üìç Regions: {len(SYDNEY_REGIONS)}\")\n",
    "    for name, coords in SYDNEY_REGIONS.items():\n",
    "        print(f\"   ‚Ä¢ {name}: {coords}\")\n",
    "    print(f\"üî• Event: Black Summer Bushfires (2019-2020)\")\n",
    "    print(f\"üåµ Context: Prolonged drought + catastrophic fire + urban expansion\")\n",
    "    print(f\"üìä Research: Bushfire, Drought, Regrowth, Deforestation\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    create_output_dirs()\n",
    "    \n",
    "    total_downloaded = 0\n",
    "    total_failed = 0\n",
    "    \n",
    "    print(f\"\\nTarget: {NUM_IMAGES} images total (~{NUM_IMAGES // len(SYDNEY_REGIONS)} per region)\")\n",
    "    print(f\"Time periods: {len(YEAR_RANGES)}\")\n",
    "    print(f\"Resolution: {SCALE}m | Format: PNG (Viewable RGB)\\n\")\n",
    "    \n",
    "    images_per_region = NUM_IMAGES // len(SYDNEY_REGIONS)\n",
    "    \n",
    "    # Process each sub-region\n",
    "    for region_name, coords in SYDNEY_REGIONS.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üå≥ Processing Region: {region_name}\")\n",
    "        print(f\"üìç Coordinates: {coords}\")\n",
    "        print(f\"üéØ Target: {images_per_region} images\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        downloaded_count = 0\n",
    "        failed_count = 0\n",
    "        \n",
    "        # Iterate through each year range for this region\n",
    "        for start_date, end_date in YEAR_RANGES:\n",
    "            if downloaded_count >= images_per_region:\n",
    "                break\n",
    "            \n",
    "            period_label = get_period_label(start_date, end_date)\n",
    "            \n",
    "            # Get the satellite collection for the period\n",
    "            collection, satellite_type = get_satellite_collection(start_date, end_date, roi, MAX_CLOUD_COVER)\n",
    "            \n",
    "            if collection is None:\n",
    "                print(f\"  {period_label}: 0 images found\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                count = collection.size().getInfo()\n",
    "                if count == 0:\n",
    "                    print(f\"  {period_label}: 0 images found\")\n",
    "                    continue\n",
    "                    \n",
    "                print(f\"  {period_label}: {count} images available\")\n",
    "                \n",
    "                # Images per period\n",
    "                if 'BLACK SUMMER' in period_label:\n",
    "                    images_per_period = min(5, count, images_per_region - downloaded_count)\n",
    "                else:\n",
    "                    images_per_period = min(3, count, images_per_region - downloaded_count)\n",
    "                    \n",
    "                if images_per_period <= 0:\n",
    "                    break\n",
    "                    \n",
    "                images = collection.limit(images_per_period).toList(images_per_period)\n",
    "                \n",
    "                for i in range(images_per_period):\n",
    "                    if downloaded_count >= images_per_region:\n",
    "                        break\n",
    "                        \n",
    "                    image = ee.Image(images.get(i))\n",
    "                    \n",
    "                    # Get date\n",
    "                    date_acquired = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                    \n",
    "                    # Filename construction\n",
    "                    period_code = period_label.split('(')[0].strip().replace(' ', '_').replace('&', '').replace('-', '')\n",
    "                    filename = f\"{OUTPUT_DIR}/rgb_images/{region_name}_{date_acquired}_{period_code}_RGB.png\"\n",
    "                    metadata_filename = f\"{OUTPUT_DIR}/metadata/{region_name}_{date_acquired}_{period_code}_meta.txt\"\n",
    "                    \n",
    "                    # Skip if exists\n",
    "                    if os.path.exists(filename):\n",
    "                        downloaded_count += 1\n",
    "                        print(f\"    ‚äô {date_acquired} (exists)\")\n",
    "                        continue\n",
    "                    \n",
    "                    print(f\"    ‚Üì {date_acquired}...\", end=' ')\n",
    "                    \n",
    "                    if download_rgb_image(image, roi, filename):\n",
    "                        save_metadata(image, metadata_filename, region_name, period_label)\n",
    "                        downloaded_count += 1\n",
    "                        print(f\"‚úì ({downloaded_count}/{images_per_region})\")\n",
    "                    else:\n",
    "                        failed_count += 1\n",
    "                    \n",
    "                    time.sleep(1.5)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚úó Error in collection processing: {str(e)[:50]}...\")\n",
    "                continue\n",
    "        \n",
    "        total_downloaded += downloaded_count\n",
    "        total_failed += failed_count\n",
    "        print(f\"\\n‚úì {region_name}: {downloaded_count} downloaded, {failed_count} failed\")\n",
    "    \n",
    "    # Final Summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DOWNLOAD COMPLETE - SYDNEY BLUE MOUNTAINS MULTI-REGION DATASET\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"‚úì Total Downloaded: {total_downloaded}/{NUM_IMAGES} images\")\n",
    "    print(f\"‚úó Total Failed: {total_failed}\")\n",
    "    print(f\"üìÅ Location: {OUTPUT_DIR}/rgb_images/\")\n",
    "    print(f\"\\nüìä Dataset Coverage:\")\n",
    "    print(f\"   ‚Ä¢ Pre-fire baseline: 2018\")\n",
    "    print(f\"   ‚Ä¢ Drought & Black Summer fires: 2019-2020\")\n",
    "    print(f\"   ‚Ä¢ Post-fire recovery: 2020-2021\")\n",
    "    print(f\"   ‚Ä¢ Long-term monitoring: 2021-2025\")\n",
    "    print(f\"\\nüó∫Ô∏è Sub-Regions Captured:\")\n",
    "    for name in SYDNEY_REGIONS.keys():\n",
    "        print(f\"   ‚Ä¢ {name}\")\n",
    "    print(f\"\\nüî¨ Recommended Analysis Indices:\")\n",
    "    print(f\"   ‚Ä¢ NBR (Normalized Burn Ratio): B8-B12 / B8+B12\")\n",
    "    print(f\"     ‚Üí Fire severity mapping, burn scar detection\")\n",
    "    print(f\"   ‚Ä¢ NDVI (Vegetation Index): B8-B4 / B8+B4\")\n",
    "    print(f\"     ‚Üí Vegetation health, regrowth monitoring\")\n",
    "    print(f\"   ‚Ä¢ EVI (Enhanced Vegetation): 2.5*(B8-B4) / (B8+6*B4-7.5*B2+1)\")\n",
    "    print(f\"     ‚Üí Drought stress, canopy density\")\n",
    "    print(f\"   ‚Ä¢ NDMI (Moisture Index): B8-B11 / B8+B11\")\n",
    "    print(f\"     ‚Üí Water stress, drought impact\")\n",
    "    print(f\"   ‚Ä¢ NDWI (Water Index): B3-B8 / B3+B8\")\n",
    "    print(f\"     ‚Üí Drought severity, water availability\")\n",
    "    print(f\"\\n‚úì Images are in standard PNG format and viewable!\")\n",
    "    print(\"All smoke, fire, and atmospheric effects are preserved.\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_sydney()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9957f1af-95e4-4b5b-9ee4-c652816d4a86",
   "metadata": {},
   "source": [
    "## Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79fa663c-ebd2-4271-9bce-54892a1ba102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Earth Engine initialized for project: glacier-probe-model-475519\n",
      "======================================================================\n",
      "üá¶üá∫ SYDNEY BLUE MOUNTAINS FRINGE IMAGE DOWNLOADER\n",
      "======================================================================\n",
      "Targeting Region: Blue_Mts_Fringe_Warragamba ([150.3, -34.15, 150.8, -33.85])\n",
      "----------------------------------------------------------------------\n",
      "‚úì Created output directories in sydney_blue_mountains_fringe_multispectral/\n",
      "\n",
      "Target: 50 images (Max Cloud Cover: 40%)\n",
      "Resolution: 10m | Output: sydney_blue_mountains_fringe_multispectral/multispectral_images/\n",
      "\n",
      " ¬†2018: 9 images available (SENTINEL2)\n",
      " ¬† ¬†‚Üì 2018-02-14... ‚úó Too large (region size issue at scale 10m). Try reducing the bounding box.\n",
      " ¬† ¬†‚Üì 2018-03-11... ‚úó Too large (region size issue at scale 10m). Try reducing the bounding box.\n",
      " ¬† ¬†‚Üì 2018-03-11... ‚úó Too large (region size issue at scale 10m). Try reducing the bounding box.\n",
      " ¬† ¬†‚Üì 2018-06-04... ‚úó Too large (region size issue at scale 10m). Try reducing the bounding box.\n",
      " ¬† ¬†‚Üì 2018-12-16... ‚úó Too large (region size issue at scale 10m). Try reducing the bounding box.\n",
      " ¬† ¬†‚Üì 2018-12-16... ‚úó Too large (region size issue at scale 10m). Try reducing the bounding box.\n",
      " ¬† ¬†‚Üì 2018-12-26... ‚úó Too large (region size issue at scale 10m). Try reducing the bounding box.\n",
      " ¬† ¬†‚Üì 2018-12-26... ‚úó Too large (region size issue at scale 10m). Try reducing the bounding box.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 615\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    612\u001b[0m     \n\u001b[1;32m    613\u001b[0m     \u001b[38;5;66;03m# --- STEP 1: DOWNLOAD IMAGES ---\u001b[39;00m\n\u001b[1;32m    614\u001b[0m     initialize_ee()\n\u001b[0;32m--> 615\u001b[0m     main_downloader()\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# --- STEP 2: PROCESS AND ANALYZE DOWNLOADED IMAGES ---\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 197\u001b[0m, in \u001b[0;36mmain_downloader\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     count \u001b[38;5;241m=\u001b[39m collection\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mgetInfo()\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ¬†\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_date[:\u001b[38;5;241m4\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: 0 images found (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msatellite_type\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/ee/computedobject.py:107\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcomputeValue(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/ee/data.py:1064\u001b[0m, in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1061\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m: serializer\u001b[38;5;241m.\u001b[39mencode(obj, for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[1;32m   1062\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[0;32m-> 1064\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _execute_cloud_call(\n\u001b[1;32m   1065\u001b[0m     _get_cloud_projects()\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;241m.\u001b[39mvalue()\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;241m.\u001b[39mcompute(body\u001b[38;5;241m=\u001b[39mbody, project\u001b[38;5;241m=\u001b[39m_get_projects_path(), prettyPrint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1068\u001b[0m )[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/ee/data.py:349\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    347\u001b[0m num_retries \u001b[38;5;241m=\u001b[39m _get_state()\u001b[38;5;241m.\u001b[39mmax_retries \u001b[38;5;28;01mif\u001b[39;00m num_retries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_retries\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    351\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/googleapiclient/http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m _retry_request(\n\u001b[1;32m    924\u001b[0m     http,\n\u001b[1;32m    925\u001b[0m     num_retries,\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sleep,\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rand,\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri),\n\u001b[1;32m    930\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod),\n\u001b[1;32m    931\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    932\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    933\u001b[0m )\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[1;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/googleapiclient/http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m http\u001b[38;5;241m.\u001b[39mrequest(uri, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    219\u001b[0m     uri,\n\u001b[1;32m    220\u001b[0m     method,\n\u001b[1;32m    221\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    222\u001b[0m     headers\u001b[38;5;241m=\u001b[39mrequest_headers,\n\u001b[1;32m    223\u001b[0m     redirections\u001b[38;5;241m=\u001b[39mredirections,\n\u001b[1;32m    224\u001b[0m     connection_type\u001b[38;5;241m=\u001b[39mconnection_type,\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    226\u001b[0m )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[1;32m    236\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/ee/_cloud_api_utils.py:78\u001b[0m, in \u001b[0;36m_Http.request\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m redirections  \u001b[38;5;66;03m# Ignored\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m   \u001b[38;5;66;03m# googleapiclient is expecting an httplib2 object, and doesn't include\u001b[39;00m\n\u001b[1;32m     75\u001b[0m   \u001b[38;5;66;03m# requests error in the list of transient errors. Therefore, transient\u001b[39;00m\n\u001b[1;32m     76\u001b[0m   \u001b[38;5;66;03m# requests errors should be converted to kinds that googleapiclient\u001b[39;00m\n\u001b[1;32m     77\u001b[0m   \u001b[38;5;66;03m# consider transient.\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m     79\u001b[0m       method, uri, data\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m     80\u001b[0m   )\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionError \u001b[38;5;28;01mas\u001b[39;00m connection_error:\n\u001b[1;32m     82\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(connection_error) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconnection_error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    788\u001b[0m     conn,\n\u001b[1;32m    789\u001b[0m     method,\n\u001b[1;32m    790\u001b[0m     url,\n\u001b[1;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    800\u001b[0m )\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:1430\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1430\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/socket.py:719\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot read from timed out object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1304\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1303\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1138\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SATELLITE IMAGE ANALYSIS SCRIPT: \n",
    "1. Downloads Raw Multispectral Data (Sentinel-2/Landsat 8/9) for Sydney Blue Mountains Fringe.\n",
    "2. Calculates Key Environmental Indices (NDVI, NBR, NDMI) for Fire, Drought, and Regrowth Analysis.\n",
    "3. Generates visualizations and statistical summaries for all downloaded images.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from pathlib import Path\n",
    "import json\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- GLOBAL CONFIGURATION ---\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "OUTPUT_DOWNLOAD_DIR = 'sydney_blue_mountains_fringe_multispectral'\n",
    "OUTPUT_FEATURE_DIR = 'sydney_blue_mountains_fringe_analysis'\n",
    "NUM_IMAGES = 50 \n",
    "SCALE = 10  # 10m for detailed analysis (Sentinel-2 resolution)\n",
    "MAX_CLOUD_COVER = 40\n",
    "\n",
    "# Greater Sydney Blue Mountains Fringe Area of Interest\n",
    "# Coordinates: [lon_min, lat_min, lon_max, lat_max]\n",
    "# Focuses on the Warragamba Catchment area, capturing fire and urban expansion.\n",
    "SYDNEY_REGION = {\n",
    "    'Blue_Mts_Fringe_Warragamba': [150.3, -34.15, 150.8, -33.85]\n",
    "}\n",
    "\n",
    "# Date ranges specifically targeting the 2019-2020 Black Summer fire, drought, and recovery periods.\n",
    "YEAR_RANGES = [\n",
    "    ('2018-01-01', '2019-01-01'), # Pre-fire/drought baseline\n",
    "    ('2019-06-01', '2020-06-01'), # Peak drought and fire period (Black Summer)\n",
    "    ('2020-06-01', '2021-06-01'), # Immediate post-fire and start of regrowth\n",
    "    ('2021-06-01', '2022-06-01'), # Continued recovery\n",
    "    ('2022-06-01', '2023-06-01'),\n",
    "    ('2023-06-01', '2024-06-01'),\n",
    "    ('2024-06-01', '2025-06-01'),\n",
    "]\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "def initialize_ee():\n",
    "    \"\"\"Initializes Earth Engine and handles authentication.\"\"\"\n",
    "    try:\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(f\"‚úì Earth Engine initialized for project: {PROJECT_ID}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Initialization failed. Attempting authentication...\")\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(f\"‚úì Authentication successful.\")\n",
    "\n",
    "# --- DOWNLOAD FUNCTIONS ---\n",
    "\n",
    "def create_output_dirs(base_dir):\n",
    "    \"\"\"Create output directory structure\"\"\"\n",
    "    Path(base_dir).mkdir(exist_ok=True)\n",
    "    Path(f\"{base_dir}/multispectral_images\").mkdir(exist_ok=True)\n",
    "    Path(f\"{base_dir}/metadata\").mkdir(exist_ok=True)\n",
    "    print(f\"‚úì Created output directories in {base_dir}/\")\n",
    "\n",
    "def get_satellite_collection(start_date, end_date, roi, max_cloud_cover):\n",
    "    \"\"\"Get Sentinel-2 or Landsat collection\"\"\"\n",
    "    # Sentinel-2 Surface Reflectance Harmonized (SR_HARMONIZED)\n",
    "    sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "\n",
    "    # Landsat 8/9 Collection 2 Tier 1 Surface Reflectance (L2)\n",
    "    landsat89 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
    "        .merge(ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')) \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUD_COVER', max_cloud_cover))\n",
    "\n",
    "    s2_count = sentinel2.size().getInfo()\n",
    "    l8_count = landsat89.size().getInfo()\n",
    "\n",
    "    # Prioritize Sentinel-2 due to higher resolution (10m)\n",
    "    if s2_count > 0:\n",
    "        return sentinel2, 'sentinel2'\n",
    "    elif l8_count > 0:\n",
    "        return landsat89, 'landsat'\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def download_raw_image(image, region, filename, satellite_type):\n",
    "    \"\"\"Downloads RAW, UNPROCESSED multispectral data as Int16 GeoTIFF.\"\"\"\n",
    "    try:\n",
    "        if satellite_type == 'sentinel2':\n",
    "            # Sentinel-2 Bands requested in the GeoTIFF download\n",
    "            bands_to_select = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\n",
    "            raw_image = image.select(bands_to_select)\n",
    "            processed = raw_image.toInt16() # 0-10000 range\n",
    "        else: # 'landsat'\n",
    "            # Landsat SR Bands requested in the GeoTIFF download\n",
    "            bands_to_select = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "            raw_image = image.select(bands_to_select)\n",
    "            processed = raw_image.toInt16() # Landsat Collection 2 scaled integers\n",
    "\n",
    "        url = processed.getDownloadURL({\n",
    "            'region': region,\n",
    "            'scale': SCALE,\n",
    "            'format': 'GEO_TIFF',\n",
    "            'crs': 'EPSG:4326' # Standard CRS for Sydney\n",
    "        })\n",
    "\n",
    "        response = requests.get(url, timeout=300)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚úó HTTP Error {response.status_code}\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if 'too large' in error_msg.lower() or 'size' in error_msg.lower():\n",
    "            print(f\"‚úó Too large (region size issue at scale {SCALE}m). Try reducing the bounding box.\")\n",
    "        else:\n",
    "            print(f\"‚úó Error: {error_msg[:50]}...\")\n",
    "        return False\n",
    "\n",
    "def save_metadata(image, filename, region_name, satellite_type):\n",
    "    \"\"\"Save image metadata\"\"\"\n",
    "    try:\n",
    "        props = image.getInfo()['properties']\n",
    "        metadata_file = filename.replace('.tif', '_metadata.txt')\n",
    "        \n",
    "        with open(metadata_file, 'w') as f:\n",
    "            f.write(f\"Region: {region_name}\\n\")\n",
    "            f.write(f\"Satellite: {satellite_type.upper()}\\n\")\n",
    "            f.write(f\"Image Type: MULTISPECTRAL (Scientific Data)\\n\") \n",
    "            \n",
    "            if satellite_type == 'sentinel2':\n",
    "                date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                f.write(f\"Date: {date}\\n\")\n",
    "                f.write(f\"Cloud Cover: {props.get('CLOUDY_PIXEL_PERCENTAGE', 'N/A')}%\\n\")\n",
    "                f.write(f\"Product ID: {props.get('PRODUCT_ID', 'N/A')}\\n\")\n",
    "                f.write(f\"Bands: ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\\n\")\n",
    "                f.write(f\"Values: Raw (0-10000 range)\\n\")\n",
    "                f.write(f\"Processing: None. Saved as Int16.\\n\")\n",
    "            else:\n",
    "                f.write(f\"Date: {props.get('DATE_ACQUIRED', 'N/A')}\\n\")\n",
    "                f.write(f\"Cloud Cover: {props.get('CLOUD_COVER', 'N/A')}%\\n\")\n",
    "                f.write(f\"Scene ID: {props.get('LANDSAT_SCENE_ID', 'N/A')}\\n\")\n",
    "                f.write(f\"Bands: ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\\n\")\n",
    "                f.write(f\"Values: Raw (Landsat Collection 2 scaled integers)\\n\")\n",
    "                f.write(f\"Processing: None. Saved as Int16.\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" ¬†‚ö† Metadata warning: {str(e)[:30]}\")\n",
    "\n",
    "def main_downloader():\n",
    "    \"\"\"Main download function for Sydney Blue Mountains Fringe\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üá¶üá∫ SYDNEY BLUE MOUNTAINS FRINGE IMAGE DOWNLOADER\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Use the new key 'Blue_Mts_Fringe_Warragamba'\n",
    "    region_name, coords = list(SYDNEY_REGION.items())[0]\n",
    "    print(f\"Targeting Region: {region_name} ({coords})\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    create_output_dirs(OUTPUT_DOWNLOAD_DIR)\n",
    "    \n",
    "    downloaded_count = 0\n",
    "    failed_count = 0\n",
    "    roi = ee.Geometry.Rectangle(coords)\n",
    "\n",
    "    print(f\"\\nTarget: {NUM_IMAGES} images (Max Cloud Cover: {MAX_CLOUD_COVER}%)\")\n",
    "    print(f\"Resolution: {SCALE}m | Output: {OUTPUT_DOWNLOAD_DIR}/multispectral_images/\\n\")\n",
    "    \n",
    "    for start_date, end_date in YEAR_RANGES:\n",
    "        if downloaded_count >= NUM_IMAGES:\n",
    "            break\n",
    "        \n",
    "        collection, satellite_type = get_satellite_collection(start_date, end_date, roi, MAX_CLOUD_COVER)\n",
    "        \n",
    "        if collection is None:\n",
    "            print(f\" ¬†{start_date[:4]}: 0 images found (S2/L8)\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            count = collection.size().getInfo()\n",
    "            if count == 0:\n",
    "                print(f\" ¬†{start_date[:4]}: 0 images found ({satellite_type.upper()})\")\n",
    "                continue\n",
    "                \n",
    "            print(f\" ¬†{start_date[:4]}: {count} images available ({satellite_type.upper()})\")\n",
    "            \n",
    "            # Limit download to distribute the total 50 over all years\n",
    "            images_to_download = min(8, count, NUM_IMAGES - downloaded_count)\n",
    "            if images_to_download <= 0:\n",
    "                break\n",
    "                \n",
    "            images = collection.limit(images_to_download).toList(images_to_download)\n",
    "            \n",
    "            for i in range(images_to_download):\n",
    "                if downloaded_count >= NUM_IMAGES:\n",
    "                    break\n",
    "                    \n",
    "                image = ee.Image(images.get(i))\n",
    "                \n",
    "                if satellite_type == 'sentinel2':\n",
    "                    date_acquired = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                else:\n",
    "                    date_acquired = image.get('DATE_ACQUIRED').getInfo()\n",
    "                \n",
    "                sat_prefix = 'S2' if satellite_type == 'sentinel2' else 'L8'\n",
    "                filename = f\"{OUTPUT_DOWNLOAD_DIR}/multispectral_images/{region_name}_{date_acquired}_{sat_prefix}_MULTI.tif\"\n",
    "                metadata_filename = f\"{OUTPUT_DOWNLOAD_DIR}/metadata/{region_name}_{date_acquired}_{sat_prefix}_MULTI_metadata.txt\"\n",
    "                \n",
    "                if os.path.exists(filename):\n",
    "                    downloaded_count += 1\n",
    "                    print(f\" ¬† ¬†‚äô {date_acquired} (exists)\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\" ¬† ¬†‚Üì {date_acquired}...\", end=' ')\n",
    "                \n",
    "                if download_raw_image(image, roi, filename, satellite_type):\n",
    "                    save_metadata(image, metadata_filename, region_name, satellite_type)\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"‚úì ({downloaded_count}/{NUM_IMAGES})\")\n",
    "                else:\n",
    "                    failed_count += 1\n",
    "                \n",
    "                time.sleep(1) # Be polite to the server\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" ¬†‚úó Error in collection processing: {str(e)[:50]}...\")\n",
    "            continue\n",
    "            \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"DOWNLOAD SUMMARY: Downloaded: {downloaded_count} | Failed: {failed_count}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# --- FEATURE EXTRACTION & VISUALIZATION FUNCTIONS ---\n",
    "\n",
    "def load_geotiff_bands(geotiff_path):\n",
    "    \"\"\"\n",
    "    Load bands from GeoTIFF. Assumes order based on the downloader script.\n",
    "    \"\"\"\n",
    "    bands = {}\n",
    "    \n",
    "    with rasterio.open(geotiff_path) as src:\n",
    "        filename = Path(geotiff_path).name\n",
    "        \n",
    "        if '_S2_' in filename:\n",
    "            band_names = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\n",
    "        elif '_L8_' in filename:\n",
    "            band_names = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "        else:\n",
    "            print(f\"‚ö† Warning: Unknown satellite type for {filename}\")\n",
    "            return bands, src.meta\n",
    "\n",
    "        for i, name in enumerate(band_names):\n",
    "            band_num = i + 1\n",
    "            if band_num <= src.count:\n",
    "                # Read the band and assign it the correct spectral name\n",
    "                bands[name] = src.read(band_num).astype(float)\n",
    "        \n",
    "        # Internal mapping for consistency in index calculations\n",
    "        if 'SR_B5' in bands and 'B8' not in bands: bands['B8'] = bands['SR_B5'] # NIR\n",
    "        if 'SR_B4' in bands and 'B4' not in bands: bands['B4'] = bands['SR_B4'] # Red\n",
    "        if 'SR_B2' in bands and 'B2' not in bands: bands['B2'] = bands['SR_B2'] # Blue\n",
    "        if 'SR_B3' in bands and 'B3' not in bands: bands['B3'] = bands['SR_B3'] # Green\n",
    "\n",
    "        return bands, src.meta\n",
    "\n",
    "def safe_band_access(bands, names):\n",
    "    \"\"\"Accesses bands, handling S2 (B4) or Landsat (SR_B4) names.\"\"\"\n",
    "    for name in names:\n",
    "        if name in bands:\n",
    "            return bands[name]\n",
    "    raise ValueError(f\"Missing required band(s): {', '.join(names)}\")\n",
    "\n",
    "def calculate_ndvi_from_bands(bands):\n",
    "    \"\"\"Calculate NDVI: (NIR - Red) / (NIR + Red)\"\"\"\n",
    "    # NIR is B8 (S2) or SR_B5 (L8) -> mapped to B8\n",
    "    # Red is B4 (S2) or SR_B4 (L8) -> mapped to B4\n",
    "    nir = bands['B8']\n",
    "    red = bands['B4']\n",
    "    ndvi = (nir - red) / (nir + red + 1e-10)\n",
    "    return np.clip(ndvi, -1, 1)\n",
    "\n",
    "def calculate_evi_from_bands(bands):\n",
    "    \"\"\"Calculate EVI: 2.5 * ((NIR - Red) / (NIR + 6*Red - 7.5*Blue + 1))\"\"\"\n",
    "    nir = bands['B8']\n",
    "    red = bands['B4']\n",
    "    blue = bands['B2']\n",
    "    evi = 2.5 * ((nir - red) / (nir + 6 * red - 7.5 * blue + 1 + 1e-10))\n",
    "    return np.clip(evi, -1, 1)\n",
    "\n",
    "def calculate_ndmi_from_bands(bands):\n",
    "    \"\"\"Calculate NDMI: (NIR - SWIR1) / (NIR + SWIR1)\"\"\"\n",
    "    nir = bands['B8']\n",
    "    swir1 = safe_band_access(bands, ['B11', 'SR_B6'])\n",
    "    ndmi = (nir - swir1) / (nir + swir1 + 1e-10)\n",
    "    return np.clip(ndmi, -1, 1)\n",
    "\n",
    "def calculate_nbr_from_bands(bands):\n",
    "    \"\"\"Calculate NBR: (NIR - SWIR2) / (NIR + SWIR2)\"\"\"\n",
    "    nir = bands['B8']\n",
    "    swir2 = safe_band_access(bands, ['B12', 'SR_B7'])\n",
    "    nbr = (nir - swir2) / (nir + swir2 + 1e-10)\n",
    "    return np.clip(nbr, -1, 1)\n",
    "\n",
    "def calculate_savi_from_bands(bands, L=0.5):\n",
    "    \"\"\"Calculate SAVI: ((NIR - Red) / (NIR + Red + L)) * (1 + L)\"\"\"\n",
    "    nir = bands['B8']\n",
    "    red = bands['B4']\n",
    "    savi = ((nir - red) / (nir + red + L + 1e-10)) * (1 + L)\n",
    "    return np.clip(savi, -1, 1)\n",
    "\n",
    "def calculate_bsi_from_bands(bands):\n",
    "    \"\"\"Calculate BSI: ((SWIR1 + Red) - (NIR + Blue)) / ((SWIR1 + Red) + (NIR + Blue))\"\"\"\n",
    "    swir1 = safe_band_access(bands, ['B11', 'SR_B6'])\n",
    "    red = bands['B4']\n",
    "    nir = bands['B8']\n",
    "    blue = bands['B2']\n",
    "    bsi = ((swir1 + red) - (nir + blue)) / ((swir1 + red) + (nir + blue) + 1e-10)\n",
    "    return np.clip(bsi, -1, 1)\n",
    "\n",
    "def calculate_all_indices_from_geotiff(geotiff_path):\n",
    "    \"\"\"Calculate all indices and RGB visualization array\"\"\"\n",
    "    bands, meta = load_geotiff_bands(geotiff_path)\n",
    "    indices = {}\n",
    "    \n",
    "    # Check for required bands before calculating. If a calculation fails, skip the index.\n",
    "    try: indices['NDVI'] = calculate_ndvi_from_bands(bands)\n",
    "    except ValueError: pass\n",
    "    try: indices['EVI'] = calculate_evi_from_bands(bands)\n",
    "    except ValueError: pass\n",
    "    try: indices['NDMI'] = calculate_ndmi_from_bands(bands)\n",
    "    except ValueError: pass\n",
    "    try: indices['NBR'] = calculate_nbr_from_bands(bands)\n",
    "    except ValueError: pass\n",
    "    try: indices['SAVI'] = calculate_savi_from_bands(bands)\n",
    "    except ValueError: pass\n",
    "    try: indices['BSI'] = calculate_bsi_from_bands(bands)\n",
    "    except ValueError: pass\n",
    "    \n",
    "    # Calculate RGB for visualization\n",
    "    try:\n",
    "        # Assuming B4 (Red), B3 (Green), B2 (Blue) are available\n",
    "        rgb = np.dstack([\n",
    "            np.clip(bands['B4'] / 3000, 0, 1), # Red (B4 or SR_B4)\n",
    "            np.clip(bands['B3'] / 3000, 0, 1), # Green (B3 or SR_B3)\n",
    "            np.clip(bands['B2'] / 3000, 0, 1)  # Blue (B2 or SR_B2)\n",
    "        ])\n",
    "        indices['RGB'] = rgb\n",
    "    except KeyError:\n",
    "        # Not enough bands for a color image\n",
    "        indices['RGB'] = None \n",
    "    \n",
    "    return indices, bands, meta\n",
    "\n",
    "# --- STATISTICS AND VISUALIZATION (functions remain the same) ---\n",
    "# NOTE: Using the versions from the user's provided code for consistency\n",
    "\n",
    "def extract_statistics_from_array(array, index_name):\n",
    "    \"\"\"Extract statistics from a numpy array\"\"\"\n",
    "    valid_data = array[~np.isnan(array)]\n",
    "    \n",
    "    if len(valid_data) == 0:\n",
    "        return {}\n",
    "    \n",
    "    return {\n",
    "        f'{index_name}_mean': float(np.mean(valid_data)),\n",
    "        f'{index_name}_median': float(np.median(valid_data)),\n",
    "        f'{index_name}_std': float(np.std(valid_data)),\n",
    "        f'{index_name}_min': float(np.min(valid_data)),\n",
    "        f'{index_name}_max': float(np.max(valid_data)),\n",
    "        f'{index_name}_p10': float(np.percentile(valid_data, 10)),\n",
    "        f'{index_name}_p25': float(np.percentile(valid_data, 25)),\n",
    "        f'{index_name}_p75': float(np.percentile(valid_data, 75)),\n",
    "        f'{index_name}_p90': float(np.percentile(valid_data, 90)),\n",
    "    }\n",
    "\n",
    "def extract_all_statistics(indices):\n",
    "    \"\"\"Extract statistics for all indices\"\"\"\n",
    "    stats = {}\n",
    "    index_names = ['NDVI', 'EVI', 'NDMI', 'NBR', 'SAVI', 'BSI']\n",
    "    for index_name in index_names:\n",
    "        if index_name in indices:\n",
    "            index_stats = extract_statistics_from_array(indices[index_name], index_name)\n",
    "            stats.update(index_stats)\n",
    "    return stats\n",
    "\n",
    "def get_index_colormap(index_name):\n",
    "    \"\"\"Get appropriate colormap for each index\"\"\"\n",
    "    colormaps = {\n",
    "        'NDVI': 'RdYlGn',\n",
    "        'EVI': 'RdYlGn',\n",
    "        'NDMI': 'RdYlBu',\n",
    "        'NDWI': 'Blues',\n",
    "        'NBR': 'RdYlGn',\n",
    "        'SAVI': 'YlGn',\n",
    "        'BSI': 'YlOrRd'\n",
    "    }\n",
    "    return colormaps.get(index_name, 'viridis')\n",
    "\n",
    "def interpret_index_value(index_name, value):\n",
    "    \"\"\"Provide interpretation for index values\"\"\"\n",
    "    interpretations = {\n",
    "        'NDVI': [\n",
    "            (0.6, 1.0, \"Dense healthy vegetation\", \"darkgreen\"),\n",
    "            (0.3, 0.6, \"Moderate vegetation\", \"green\"),\n",
    "            (0.1, 0.3, \"Sparse vegetation\", \"yellow\"),\n",
    "            (-1.0, 0.1, \"Bare soil/water/urban\", \"brown\")\n",
    "        ],\n",
    "        'EVI': [\n",
    "            (0.5, 1.0, \"High biomass, dense canopy\", \"darkgreen\"),\n",
    "            (0.3, 0.5, \"Moderate vegetation density\", \"green\"),\n",
    "            (-1.0, 0.3, \"Low/stressed vegetation\", \"orange\")\n",
    "        ],\n",
    "        'NDMI': [\n",
    "            (0.3, 1.0, \"High moisture, healthy\", \"blue\"),\n",
    "            (0.0, 0.3, \"Moderate moisture\", \"lightblue\"),\n",
    "            (-1.0, 0.0, \"Water stress, drought\", \"red\")\n",
    "        ],\n",
    "        'NBR': [\n",
    "            (0.3, 1.0, \"Healthy, unburned\", \"darkgreen\"),\n",
    "            (0.1, 0.3, \"Low severity burn/recovery\", \"yellow\"),\n",
    "            (-0.1, 0.1, \"Moderate severity burn\", \"orange\"),\n",
    "            (-1.0, -0.1, \"High severity burn\", \"red\")\n",
    "        ],\n",
    "        'BSI': [\n",
    "            (0.2, 1.0, \"High bare soil exposure\", \"brown\"),\n",
    "            (0.0, 0.2, \"Moderate soil exposure\", \"tan\"),\n",
    "            (-1.0, 0.0, \"Well vegetated\", \"green\")\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if index_name not in interpretations:\n",
    "        return \"Value\", \"gray\"\n",
    "    \n",
    "    for min_val, max_val, desc, color in interpretations[index_name]:\n",
    "        if min_val <= value < max_val:\n",
    "            return desc, color\n",
    "    \n",
    "    return \"Value\", \"gray\"\n",
    "\n",
    "\n",
    "def visualize_image_with_features(image_path, indices=None, stats=None, \n",
    "                                  save_path=None, show_plot=True):\n",
    "    \"\"\"Visualize image with all calculated features\"\"\"\n",
    "    \n",
    "    # If indices not provided, calculate them (only works for .tif)\n",
    "    if indices is None:\n",
    "        if str(image_path).endswith('.tif'):\n",
    "            indices, bands, meta = calculate_all_indices_from_geotiff(image_path)\n",
    "        else:\n",
    "            print(\"‚ö† Please provide GeoTIFF for index calculation\")\n",
    "            indices = {}\n",
    "    \n",
    "    # Calculate statistics if not provided\n",
    "    if stats is None and indices:\n",
    "        stats = extract_all_statistics(indices)\n",
    "    \n",
    "    rgb_image = indices.get('RGB', None)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = GridSpec(3, 4, figure=fig, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Title\n",
    "    fig.suptitle(f'Satellite Image Feature Analysis\\n{Path(image_path).name}', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot RGB image (large, top-left)\n",
    "    if rgb_image is not None:\n",
    "        ax_rgb = fig.add_subplot(gs[0:2, 0:2])\n",
    "        ax_rgb.imshow(rgb_image)\n",
    "        ax_rgb.set_title('RGB True Color Image (0-3000 scaled)', fontsize=14, fontweight='bold')\n",
    "        ax_rgb.axis('off')\n",
    "    \n",
    "    # Plot individual indices\n",
    "    index_names = ['NDVI', 'EVI', 'NDMI', 'NBR', 'SAVI', 'BSI']\n",
    "    positions = [\n",
    "        (0, 2), (0, 3),  # Top right\n",
    "        (1, 2), (1, 3),  # Middle right\n",
    "        (2, 0), (2, 1)   # Bottom row\n",
    "    ]\n",
    "    \n",
    "    # We use a combined list and skip the last position in the bottom row for the stats panel.\n",
    "    for idx, (index_name, (row, col)) in enumerate(zip(index_names, positions)):\n",
    "        if index_name not in indices:\n",
    "            continue\n",
    "            \n",
    "        ax = fig.add_subplot(gs[row, col])\n",
    "        \n",
    "        index_data = indices[index_name]\n",
    "        cmap = get_index_colormap(index_name)\n",
    "        \n",
    "        im = ax.imshow(index_data, cmap=cmap, vmin=-1, vmax=1)\n",
    "        ax.set_title(f'{index_name}', fontsize=12, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.ax.tick_params(labelsize=8)\n",
    "        \n",
    "        # Add statistics text\n",
    "        if stats and f'{index_name}_mean' in stats:\n",
    "            mean_val = stats[f'{index_name}_mean']\n",
    "            interpretation, color = interpret_index_value(index_name, mean_val)\n",
    "            \n",
    "            text = f\"Mean: {mean_val:.3f}\\n{interpretation}\"\n",
    "            ax.text(0.02, 0.98, text, transform=ax.transAxes,\n",
    "                    fontsize=9, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor=color, alpha=0.3))\n",
    "    \n",
    "    # Add statistics panel (covers the remaining bottom-right space)\n",
    "    ax_stats = fig.add_subplot(gs[2, 2:]) # Span the remaining two columns\n",
    "    ax_stats.axis('off')\n",
    "    \n",
    "    if stats:\n",
    "        stats_text = \"üìä SUMMARY STATISTICS\\n\" + \"=\"*25 + \"\\n\"\n",
    "        \n",
    "        for index_name in ['NDVI', 'NDMI', 'NBR', 'BSI']:\n",
    "            if f'{index_name}_mean' in stats:\n",
    "                mean_val = stats[f'{index_name}_mean']\n",
    "                std_val = stats[f'{index_name}_std']\n",
    "                stats_text += f\"\\n{index_name}:\\n\"\n",
    "                stats_text += f\" ¬†Œº={mean_val:.3f} œÉ={std_val:.3f}\\n\"\n",
    "        \n",
    "        ax_stats.text(0.05, 0.95, stats_text, transform=ax_stats.transAxes,\n",
    "                      fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                      bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def batch_process_images(image_dir, output_dir=OUTPUT_FEATURE_DIR, pattern='*.tif'):\n",
    "    \"\"\"\n",
    "    Process multiple images from a directory, calculate features, and save results.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìÅ BATCH PROCESSING STARTED\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    image_paths = list(Path(image_dir).glob(pattern))\n",
    "    print(f\"Found {len(image_paths)} GeoTIFF images to process.\")\n",
    "    \n",
    "    all_stats = []\n",
    "    \n",
    "    for i, image_path in enumerate(image_paths, 1):\n",
    "        print(f\"\\n[{i}/{len(image_paths)}] Processing: {image_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            indices, bands, meta = calculate_all_indices_from_geotiff(str(image_path))\n",
    "            stats = extract_all_statistics(indices)\n",
    "            stats['filename'] = image_path.name\n",
    "            stats['date'] = image_path.stem.split('_')[2] if '_' in image_path.stem else 'unknown'\n",
    "            \n",
    "            all_stats.append(stats)\n",
    "            \n",
    "            # Create visualization (show_plot=False for batch mode)\n",
    "            viz_path = Path(output_dir) / f\"{image_path.stem}_viz.png\"\n",
    "            visualize_image_with_features(\n",
    "                str(image_path), \n",
    "                indices=indices, \n",
    "                stats=stats,\n",
    "                save_path=viz_path,\n",
    "                show_plot=False\n",
    "            )\n",
    "            print(f\"‚úì Visualization saved: {viz_path.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error processing {image_path.name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Save all statistics to CSV\n",
    "    if all_stats:\n",
    "        df = pd.DataFrame(all_stats)\n",
    "        csv_path = Path(output_dir) / 'all_features_summary.csv'\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"\\n‚úì All features saved to: {csv_path}\")\n",
    "        print(f\"üìä Total images processed: {len(all_stats)}\")\n",
    "    \n",
    "    return all_stats\n",
    "\n",
    "\n",
    "# --- MAIN EXECUTION BLOCK ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # --- STEP 1: DOWNLOAD IMAGES ---\n",
    "    initialize_ee()\n",
    "    main_downloader()\n",
    "    \n",
    "    # --- STEP 2: PROCESS AND ANALYZE DOWNLOADED IMAGES ---\n",
    "    print(\"\\n\\n\" + \"#\" * 70)\n",
    "    print(\"STARTING FEATURE EXTRACTION & ANALYSIS\")\n",
    "    print(\"#\" * 70)\n",
    "    \n",
    "    image_folder_path = Path(OUTPUT_DOWNLOAD_DIR) / 'multispectral_images'\n",
    "    \n",
    "    if image_folder_path.exists() and any(image_folder_path.glob('*.tif')):\n",
    "        # Process downloaded GeoTIFF files\n",
    "        feature_stats = batch_process_images(\n",
    "            image_dir=str(image_folder_path),\n",
    "            output_dir=OUTPUT_FEATURE_DIR\n",
    "        )\n",
    "    else:\n",
    "        print(f\"\\nüî¥ ERROR: No GeoTIFF files found in {image_folder_path}. Run the downloader first!\")\n",
    "        print(\"Please check the download process for errors and ensure GeoTIFFs were saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be25a49-9f82-421a-ae73-58070b330688",
   "metadata": {},
   "source": [
    "## Objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24970398-99ee-4963-9b5f-186e9f905e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üñºÔ∏è  PROCESSING IMAGE: Penrith_Urban_Edge_2019-06-09_DROUGHT__BLACK_SUMMER_FIRES_RGB.png\n",
      "================================================================================\n",
      "\n",
      "üìä Processing: Penrith_Urban_Edge_2019-06-09_DROUGHT__BLACK_SUMMER_FIRES_RGB.png\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'B8'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../sample/sydney_blue_mountains_fringe_rgb/rgb_images/Penrith_Urban_Edge_2019-06-09_DROUGHT__BLACK_SUMMER_FIRES_RGB.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m process_single_image(image_path, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_processed_output_1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 363\u001b[0m, in \u001b[0;36mprocess_single_image\u001b[0;34m(image_path, output_dir)\u001b[0m\n\u001b[1;32m    360\u001b[0m Path(output_dir)\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Calculate indices\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m indices, bands, meta \u001b[38;5;241m=\u001b[39m calculate_all_indices_from_geotiff(image_path)\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì Indices calculated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Extract statistics\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 125\u001b[0m, in \u001b[0;36mcalculate_all_indices_from_geotiff\u001b[0;34m(geotiff_path)\u001b[0m\n\u001b[1;32m    122\u001b[0m bands, meta \u001b[38;5;241m=\u001b[39m load_geotiff_bands(geotiff_path)\n\u001b[1;32m    124\u001b[0m indices \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 125\u001b[0m indices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNDVI\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m calculate_ndvi_from_bands(bands)\n\u001b[1;32m    126\u001b[0m indices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEVI\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m calculate_evi_from_bands(bands)\n\u001b[1;32m    127\u001b[0m indices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNDMI\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m calculate_ndmi_from_bands(bands)\n",
      "Cell \u001b[0;32mIn[20], line 65\u001b[0m, in \u001b[0;36mcalculate_ndvi_from_bands\u001b[0;34m(bands)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcalculate_ndvi_from_bands\u001b[39m(bands):\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate NDVI from band arrays\"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     nir \u001b[38;5;241m=\u001b[39m bands[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB8\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     66\u001b[0m     red \u001b[38;5;241m=\u001b[39m bands[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     67\u001b[0m     ndvi \u001b[38;5;241m=\u001b[39m (nir \u001b[38;5;241m-\u001b[39m red) \u001b[38;5;241m/\u001b[39m (nir \u001b[38;5;241m+\u001b[39m red \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'B8'"
     ]
    }
   ],
   "source": [
    "\n",
    "image_path = \"../sample/sydney_blue_mountains_fringe_rgb/rgb_images/Penrith_Urban_Edge_2019-06-09_DROUGHT__BLACK_SUMMER_FIRES_RGB.png\"\n",
    "process_single_image(image_path, output_dir='sample_processed_output_1')\n",
    "print(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565b7bf-8b18-45bb-92ad-4b06e875984b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
